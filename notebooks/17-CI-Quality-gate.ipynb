{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30a056de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "import instructor\n",
    "from openai import OpenAI\n",
    "from langchain_core.messages import AIMessage, ToolMessage\n",
    "\n",
    "import json\n",
    "\n",
    "from typing import List, Dict, Any, Annotated, Optional\n",
    "from operator import add\n",
    "from jinja2 import Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b5b3859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # This loads variables from .env into the environment\n",
    "\n",
    "import os\n",
    "api_key = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"LANGSMITH_API_KEY environment variable is not set. Please set it before running this cell.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f0768ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    api_key = input(\"Please enter your OpenAI API key: \").strip()\n",
    "    os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "    if not api_key:\n",
    "        raise ValueError(\"API key is required.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6b5609",
   "metadata": {},
   "source": [
    "### Create Coordinator evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b59f055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lc_messages_to_regular_messages(msg):\n",
    "\n",
    "    if isinstance(msg, dict):\n",
    "        \n",
    "        if msg.get(\"role\") == \"user\":\n",
    "            return {\"role\": \"user\", \"content\": msg[\"content\"]}\n",
    "        elif msg.get(\"role\") == \"assistant\":\n",
    "            return {\"role\": \"assistant\", \"content\": msg[\"content\"]}\n",
    "        elif msg.get(\"role\") == \"tool\":\n",
    "            return {\n",
    "                \"role\": \"tool\", \n",
    "                \"content\": msg[\"content\"], \n",
    "                \"tool_call_id\": msg.get(\"tool_call_id\")\n",
    "            }\n",
    "        \n",
    "    elif isinstance(msg, AIMessage):\n",
    "\n",
    "        result = {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": msg.content\n",
    "        }\n",
    "        \n",
    "        if hasattr(msg, 'tool_calls') and msg.tool_calls and len(msg.tool_calls) > 0 and not msg.tool_calls[0].get(\"name\").startswith(\"functions.\"):\n",
    "            result[\"tool_calls\"] = [\n",
    "                {\n",
    "                    \"id\": tc[\"id\"],\n",
    "                    \"type\": \"function\",\n",
    "                    \"function\": {\n",
    "                        \"name\": tc[\"name\"].replace(\"functions.\", \"\"),\n",
    "                        \"arguments\": json.dumps(tc[\"args\"])\n",
    "                    }\n",
    "                }\n",
    "                for tc in msg.tool_calls\n",
    "            ]\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    elif isinstance(msg, ToolMessage):\n",
    "\n",
    "        return {\"role\": \"tool\", \"content\": msg.content, \"tool_call_id\": msg.tool_call_id}\n",
    "    \n",
    "    else:\n",
    "\n",
    "        return {\"role\": \"user\", \"content\": str(msg)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61defb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCPToolCall(BaseModel):\n",
    "    name: str\n",
    "    arguments: dict\n",
    "    server: str\n",
    "\n",
    "\n",
    "class ToolCall(BaseModel):\n",
    "    name: str\n",
    "    arguments: dict\n",
    "\n",
    "\n",
    "class RAGUsedContext(BaseModel):\n",
    "    id: str\n",
    "    description: str\n",
    "\n",
    "\n",
    "class Delegation(BaseModel):\n",
    "    agent: str\n",
    "    task: str = Field(default=\"\")\n",
    "\n",
    "\n",
    "class CoordinatorAgentResponse(BaseModel):\n",
    "    next_agent: str\n",
    "    plan: list[Delegation]\n",
    "    final_answer: bool = Field(default=False)\n",
    "    answer: str\n",
    "\n",
    "\n",
    "class State(BaseModel):\n",
    "    messages: Annotated[List[Any], add] = []\n",
    "    answer: str = \"\"\n",
    "    product_qa_iteration: int = Field(default=0)\n",
    "    shopping_cart_iteration: int = Field(default=0)\n",
    "    coordinator_iteration: int = Field(default=0)\n",
    "    product_qa_final_answer: bool = Field(default=False)\n",
    "    shopping_cart_final_answer: bool = Field(default=False)\n",
    "    coordinator_final_answer: bool = Field(default=False)\n",
    "    product_qa_available_tools: List[Dict[str, Any]] = []\n",
    "    shopping_cart_available_tools: List[Dict[str, Any]] = []\n",
    "    mcp_tool_calls: Optional[List[MCPToolCall]] = Field(default_factory=list)\n",
    "    tool_calls: Optional[List[ToolCall]] = Field(default_factory=list)\n",
    "    retrieved_context_ids: List[RAGUsedContext] = Field(default_factory=list)\n",
    "    trace_id: str = \"\"\n",
    "    user_id: str = \"\"\n",
    "    cart_id: str = \"\"\n",
    "    plan: List[Delegation] = Field(default_factory=list)\n",
    "    next_agent: str = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4c6a35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordinator_agent_node(state) -> dict:\n",
    "\n",
    "   prompt_template = \"\"\"You are a Coordinator Agent as part of a shopping assistant.\n",
    "\n",
    "Your role is to create plans for solving user queries and delegate the tasks accordingly.\n",
    "You will be given a conversation history, your task is to create a plan for solving the user's query.\n",
    "After the plan is created, you should output the next agent to invoke and the task to be performed by that agent.\n",
    "Once an agent finishes its task, you will be handed the control back, you should then review the conversation history and revise the plan.\n",
    "If there is a sequence of tasks to be performed by a single agent, you should combine them into a single task.\n",
    "\n",
    "The possible agents are:\n",
    "\n",
    "- product_qa_agent: The user is asking a question about a product. This can be a question about available products, their specifications, user reviews etc.\n",
    "- shopping_cart_agent: The user is asking to add or remove items from the shopping cart or questions about the current shopping cart.\n",
    "\n",
    "CRITICAL RULES:\n",
    "- If next_agent is \"\", final_answer MUST be false\n",
    "(You cannot delegate the task to an agent and return to the user in the same response)\n",
    "- If final_answer is true, next_agent MUST be \"\"\n",
    "(You must wait for agent results before returning to user)\n",
    "- If you need to call other agents before answering, set:\n",
    "next_agent=\"...\", final_answer=false\n",
    "- After receiving agent results, you can then set:\n",
    "next_agent=\"\", final_answer=true\n",
    "\n",
    "Additional instructions:\n",
    "\n",
    "- Write the plan to the plan field.\n",
    "- Write the next agent to invoke to the next_agent field.\n",
    "- Once you have all the information needed to answer the user's query, you should set the final_answer field to True and output the answer to the user's query.\n",
    "- Never set final_answer to true if the plan is not complete.\n",
    "- You should output the next_agent field as well as the plan field.\n",
    "\"\"\"\n",
    "\n",
    "   prompt = Template(prompt_template).render()\n",
    "\n",
    "   messages = state.messages\n",
    "\n",
    "   conversation = []\n",
    "\n",
    "   for msg in messages:\n",
    "      conversation.append(lc_messages_to_regular_messages(msg))\n",
    "\n",
    "   client = instructor.from_openai(OpenAI())\n",
    "\n",
    "   response, raw_response = client.chat.completions.create_with_completion(\n",
    "        model=\"gpt-4.1\",\n",
    "        response_model=CoordinatorAgentResponse,\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt}, *conversation],\n",
    "        temperature=0,\n",
    "   )\n",
    "\n",
    "   if response.final_answer:\n",
    "      ai_message = [AIMessage(\n",
    "         content=response.answer,\n",
    "      )]\n",
    "   else:\n",
    "      ai_message = []\n",
    "\n",
    "   return {\n",
    "      \"messages\": ai_message,\n",
    "      \"answer\": response.answer,\n",
    "      \"next_agent\": response.next_agent,\n",
    "      \"plan\": response.plan,\n",
    "      \"coordinator_final_answer\": response.final_answer,\n",
    "      \"coordinator_iteration\": state.coordinator_iteration + 1,\n",
    "      \"trace_id\": \"\",\n",
    "   }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2e603e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "import os\n",
    "\n",
    "ls_client = Client(api_key=os.environ[\"LANGSMITH_API_KEY\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9176c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_agent_evaluator(run, example):\n",
    "\n",
    "    next_agent_match = run.outputs[\"next_agent\"] == example.outputs[\"next_agent\"]\n",
    "    final_answer_match = run.outputs[\"coordinator_final_answer\"] == example.outputs[\"coordinator_final_answer\"]\n",
    "\n",
    "    return next_agent_match and final_answer_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b6631db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mcq/Development/AIML/SwirlAI/AI_bootcamp_summer_2025/01-ai-engineering-bootcamp/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'coordinator-evaluation-dataset-97df453a' at:\n",
      "https://smith.langchain.com/o/8f1e49b5-0c40-40cc-93ed-220dd6b1054e/datasets/f4469453-7001-4a34-b117-1958b00eaad7/compare?selectedSessions=bd130ba6-edd8-4233-a898-7994377cdcf0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:17,  1.73s/it]\n"
     ]
    }
   ],
   "source": [
    "results = ls_client.evaluate(\n",
    "    lambda x: coordinator_agent_node(State(messages=x[\"messages\"])),\n",
    "    data=\"coordinator-evaluation-dataset\",\n",
    "    evaluators=[next_agent_evaluator],\n",
    "    experiment_prefix=\"coordinator-evaluation-dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9dc7ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'coordinator-evaluation-dataset-97df453a'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e3c3795",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_resp = ls_client.read_project(\n",
    "    project_name=results.experiment_name, include_stats=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7cd27da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_resp.feedback_stats[\"next_agent_evaluator\"][\"avg\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "01-ai-engineering-bootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
