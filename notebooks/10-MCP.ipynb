{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55c65ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastmcp import Client\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Prefetch, Filter, FieldCondition, MatchText, FusionQuery\n",
    "\n",
    "from langsmith import traceable, get_current_run_tree\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "from langchain_core.messages import AIMessage, ToolMessage\n",
    "\n",
    "from jinja2 import Template\n",
    "from typing import Literal, Dict, Any, Annotated, List, Optional\n",
    "from IPython.display import Image, display\n",
    "from operator import add\n",
    "from openai import OpenAI\n",
    "\n",
    "import openai\n",
    "\n",
    "import random\n",
    "import ast\n",
    "import inspect\n",
    "import instructor\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d8cdd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    api_key = input(\"Please enter your OpenAI API key: \").strip()\n",
    "    os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "    if not api_key:\n",
    "        raise ValueError(\"API key is required.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35535ff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b075a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdc0aeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(\"http://localhost:8001/mcp\")\n",
    "\n",
    "async with client:\n",
    "    tools = await client.list_tools()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecca2309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tool(name='get_formatted_item_context', title=None, description='Get the top k context, each representing an inventory item for a given query.\\n\\nArgs:\\n    query: The query to get the top k context for\\n    top_k: The number of context chunks to retrieve, works best with 5 or more\\n\\nReturns:\\n    A string of the top k context chunks with IDs prepending each chunk, each representing an inventory item for a given query.', inputSchema={'properties': {'query': {'title': 'Query', 'type': 'string'}, 'top_k': {'default': 5, 'title': 'Top K', 'type': 'integer'}}, 'required': ['query'], 'type': 'object'}, outputSchema={'properties': {'result': {'title': 'Result', 'type': 'string'}}, 'required': ['result'], 'title': '_WrappedResult', 'type': 'object', 'x-fastmcp-wrap-result': True}, annotations=None, meta={'_fastmcp': {'tags': []}})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6499dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_docstring_params(docstring: str) -> Dict[str, str]:\n",
    "    \"\"\"Extract parameter descriptions from docstring (handles both Args: and Parameters: formats).\"\"\"\n",
    "    params = {}\n",
    "    lines = docstring.split('\\n')\n",
    "    in_params = False\n",
    "    current_param = None\n",
    "    \n",
    "    for line in lines:\n",
    "        stripped = line.strip()\n",
    "        \n",
    "        # Check for parameter section start\n",
    "        if stripped in ['Args:', 'Arguments:', 'Parameters:', 'Params:']:\n",
    "            in_params = True\n",
    "            current_param = None\n",
    "        elif stripped.startswith('Returns:') or stripped.startswith('Raises:'):\n",
    "            in_params = False\n",
    "        elif in_params:\n",
    "            # Parse parameter line (handles \"param: desc\" and \"- param: desc\" formats)\n",
    "            if ':' in stripped and (stripped[0].isalpha() or stripped.startswith(('-', '*'))):\n",
    "                param_name = stripped.lstrip('- *').split(':')[0].strip()\n",
    "                param_desc = ':'.join(stripped.lstrip('- *').split(':')[1:]).strip()\n",
    "                params[param_name] = param_desc\n",
    "                current_param = param_name\n",
    "            elif current_param and stripped:\n",
    "                # Continuation of previous parameter description\n",
    "                params[current_param] += ' ' + stripped\n",
    "    \n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "770b73d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'The query to get the top k context for',\n",
       " 'top_k': 'The number of context chunks to retrieve, works best with 5 or more'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_docstring_params(tools[0].description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d1969c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_tool_descriptions_from_mcp_servers(mcp_servers: list[str]) -> list[dict]:\n",
    "\n",
    "    tool_descriptions = []\n",
    "\n",
    "    for server in mcp_servers:\n",
    "\n",
    "        client = Client(server)\n",
    "\n",
    "        async with client:\n",
    "\n",
    "            tools = await client.list_tools()\n",
    "\n",
    "            for tool in tools:\n",
    "                \n",
    "                result = {\n",
    "                    \"name\": \"\",\n",
    "                    \"description\": \"\",\n",
    "                    \"parameters\": {\"type\": \"object\", \"properties\": {}},\n",
    "                    \"required\": [],\n",
    "                    \"returns\": {\"type\": \"string\", \"description\": \"\"},\n",
    "                    \"server\": server\n",
    "                }\n",
    "\n",
    "                result[\"name\"] = tool.name\n",
    "                result[\"required\"] = tool.inputSchema.get(\"required\", [])\n",
    "\n",
    "                ## Get Description\n",
    "\n",
    "                description = tool.description.split(\"\\n\\n\")[0]\n",
    "                result[\"description\"] = description\n",
    "\n",
    "\n",
    "                ## Get Returns\n",
    "\n",
    "                returns = tool.description.split(\"Returns:\")[1].strip()\n",
    "                result[\"returns\"][\"description\"] = returns\n",
    "\n",
    "                ## Get parameters\n",
    "\n",
    "                property_descriptions = parse_docstring_params(tool.description)\n",
    "                properties = tool.inputSchema.get(\"properties\", {})\n",
    "                for key, value in properties.items():\n",
    "                    properties[key][\"description\"] = property_descriptions.get(key, \"\")\n",
    "\n",
    "                result[\"parameters\"][\"properties\"] = properties\n",
    "\n",
    "                tool_descriptions.append(result)\n",
    "\n",
    "    return tool_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abe90e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73d9b961",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_servers = [\"http://localhost:8001/mcp\", \"http://localhost:8002/mcp\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "550aafd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xm/dt7ng36s29d8t3bfld7kp7w80000gn/T/ipykernel_86303/481510395.py:1: RuntimeWarning: coroutine 'get_tool_descriptions_from_mcp_servers' was never awaited\n",
      "  tool_descriptions = await get_tool_descriptions_from_mcp_servers(mcp_servers)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "tool_descriptions = await get_tool_descriptions_from_mcp_servers(mcp_servers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e554023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0dda9a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'get_formatted_item_context',\n",
       "  'description': 'Get the top k context, each representing an inventory item for a given query.',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'query': {'title': 'Query',\n",
       "     'type': 'string',\n",
       "     'description': 'The query to get the top k context for'},\n",
       "    'top_k': {'default': 5,\n",
       "     'title': 'Top K',\n",
       "     'type': 'integer',\n",
       "     'description': 'The number of context chunks to retrieve, works best with 5 or more'}}},\n",
       "  'required': ['query'],\n",
       "  'returns': {'type': 'string',\n",
       "   'description': 'A string of the top k context chunks with IDs prepending each chunk, each representing an inventory item for a given query.'},\n",
       "  'server': 'http://localhost:8001/mcp'},\n",
       " {'name': 'get_formatted_review_context',\n",
       "  'description': 'Get the top k reviews matching a query for a list of prefiltered items.',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'query': {'title': 'Query',\n",
       "     'type': 'string',\n",
       "     'description': 'The query to get the top k reviews for'},\n",
       "    'item_list': {'items': {'type': 'string'},\n",
       "     'title': 'Item List',\n",
       "     'type': 'array',\n",
       "     'description': 'The list of item IDs to prefilter for before running the query'},\n",
       "    'top_k': {'default': 20,\n",
       "     'title': 'Top K',\n",
       "     'type': 'integer',\n",
       "     'description': 'The number of reviews to retrieve, this should be at least 20 if multiple items are prefiltered'}}},\n",
       "  'required': ['query', 'item_list'],\n",
       "  'returns': {'type': 'string',\n",
       "   'description': 'A string of the top k context chunks with IDs prepending each chunk, each representing an inventory item for a given query.'},\n",
       "  'server': 'http://localhost:8002/mcp'}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_descriptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629e4ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "25e42619",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToolCall(BaseModel):\n",
    "    name: str\n",
    "    arguments: dict\n",
    "    server: str\n",
    "\n",
    "class RAGUsedContext(BaseModel):\n",
    "    id: int\n",
    "    description: str\n",
    "\n",
    "class AgentResponse(BaseModel):\n",
    "    answer: str\n",
    "    tool_calls: List[ToolCall] = Field(default_factory=list)\n",
    "    final_answer: bool = Field(default=False)\n",
    "    retrieved_context_ids: List[RAGUsedContext]\n",
    "\n",
    "class State(BaseModel):\n",
    "    messages: Annotated[List[Any], add] = []\n",
    "    answer: str = \"\"\n",
    "    iteration: int = Field(default=0)\n",
    "    final_answer: bool = Field(default=False)\n",
    "    available_tools: List[Dict[str, Any]] = []\n",
    "    tool_calls: Optional[List[ToolCall]] = Field(default_factory=list)\n",
    "    retrieved_context_ids: Annotated[List[RAGUsedContext], add] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72636ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c78d1add",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(\n",
    "    name=\"agent_node\",\n",
    "    run_type=\"llm\",\n",
    "    metadata={\"ls_provider\": \"openai\", \"ls_model_name\": \"gpt-4.1-mini\"}\n",
    ")\n",
    "def agent_node(state: State) -> dict:\n",
    "\n",
    "   prompt_template =  \"\"\"You are a shopping assistant that can answer questions about the products in stock.\n",
    "\n",
    "You will be given a question and a list of tools you can use to answer that question.\n",
    "\n",
    "<Available tools>\n",
    "{{ available_tools | tojson }}\n",
    "</Available tools>\n",
    "\n",
    "After the tools are used you will get the outputs from the tools.\n",
    "\n",
    "When you need to use a tool, format your response as:\n",
    "\n",
    "<tool_call>\n",
    "{\"name\": \"tool_name\", \"arguments\": {...}}\n",
    "</tool_call>\n",
    "\n",
    "Use names specifically provided in the available tools. Don't add any additional text to the names.\n",
    "\n",
    "You should tend to use tools when additional information is needed to answer the question.\n",
    "\n",
    "If you set final_answer to True, you should not use any tools.\n",
    "\n",
    "Instructions:\n",
    "- You need to answer the question based on the retrieved context using the available tools only.\n",
    "- Never use word context and refer to it as the available products.\n",
    "- You should only answer questions about the products in stock. If the question is not about the products in stock, you should ask for clarification.\n",
    "- As a final output you need to provide:\n",
    "\n",
    "* The answer to the question based on the retrieved context.\n",
    "* The list of the indexes from the chunks returned from all tool calls that were used to answer the question. If more than one chunk was used to compile the answer from a single tool call, be sure to return all of them.\n",
    "* Short description of the item based on the retrieved context.\n",
    "\n",
    "- The answer to the question should contain detailed information about the product and returned with detailed specification in bullet points.\n",
    "- The short description should have the name of the item.\n",
    "- If the user's request requires using a tool, set tool_calls with the appropriate function name and arguments.\n",
    "- If you have all the information needed to provide a complete answer, set final_answer to True.\n",
    "\"\"\"\n",
    "\n",
    "   template = Template(prompt_template)\n",
    "   \n",
    "   prompt = template.render(\n",
    "      available_tools=state.available_tools\n",
    "   )\n",
    "\n",
    "   messages = state.messages\n",
    "\n",
    "   conversation = []\n",
    "\n",
    "   for msg in messages:\n",
    "      conversation.append(lc_messages_to_regular_messages(msg))\n",
    "\n",
    "   client = instructor.from_openai(OpenAI())\n",
    "\n",
    "   response, raw_response = client.chat.completions.create_with_completion(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        response_model=AgentResponse,\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt}, *conversation],\n",
    "        temperature=0.5,\n",
    "   )\n",
    "\n",
    "   if response.tool_calls:\n",
    "      tool_calls = []\n",
    "      for i, tc in enumerate(response.tool_calls):\n",
    "         tool_calls.append({\n",
    "               \"id\": f\"call_{i}\",\n",
    "               \"name\": tc.name,\n",
    "               \"args\": tc.arguments\n",
    "         })\n",
    "\n",
    "      ai_message = AIMessage(\n",
    "         content=response.answer,\n",
    "         tool_calls=tool_calls\n",
    "         )\n",
    "   else:\n",
    "      ai_message = AIMessage(\n",
    "         content=response.answer,\n",
    "      )\n",
    "\n",
    "   return {\n",
    "      \"messages\": [ai_message],\n",
    "      \"tool_calls\": response.tool_calls,\n",
    "      \"iteration\": state.iteration + 1,\n",
    "      \"answer\": response.answer,\n",
    "      \"final_answer\": response.final_answer,\n",
    "      \"retrieved_context_ids\": response.retrieved_context_ids\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1537c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ed6e5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_router(state: State) -> str:\n",
    "    \"\"\"Decide whether to continue or end\"\"\"\n",
    "    \n",
    "    if state.final_answer:\n",
    "        return \"end\"\n",
    "    elif state.iteration > 2:\n",
    "        return \"end\"\n",
    "    elif len(state.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    else:\n",
    "        return \"end\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f61cea26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lc_messages_to_regular_messages(msg):\n",
    "\n",
    "    if isinstance(msg, dict):\n",
    "        \n",
    "        if msg.get(\"role\") == \"user\":\n",
    "            return {\"role\": \"user\", \"content\": msg[\"content\"]}\n",
    "        elif msg.get(\"role\") == \"assistant\":\n",
    "            return {\"role\": \"assistant\", \"content\": msg[\"content\"]}\n",
    "        elif msg.get(\"role\") == \"tool\":\n",
    "            return {\n",
    "                \"role\": \"tool\", \n",
    "                \"content\": msg[\"content\"], \n",
    "                \"tool_call_id\": msg.get(\"tool_call_id\")\n",
    "            }\n",
    "        \n",
    "    elif isinstance(msg, AIMessage):\n",
    "\n",
    "        result = {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": msg.content\n",
    "        }\n",
    "        \n",
    "        if hasattr(msg, 'tool_calls') and msg.tool_calls and len(msg.tool_calls) > 0 and not msg.tool_calls[0].get(\"name\").startswith(\"functions.\"):\n",
    "            result[\"tool_calls\"] = [\n",
    "                {\n",
    "                    \"id\": tc[\"id\"],\n",
    "                    \"type\": \"function\",\n",
    "                    \"function\": {\n",
    "                        \"name\": tc[\"name\"].replace(\"functions.\", \"\"),\n",
    "                        \"arguments\": json.dumps(tc[\"args\"])\n",
    "                    }\n",
    "                }\n",
    "                for tc in msg.tool_calls\n",
    "            ]\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    elif isinstance(msg, ToolMessage):\n",
    "\n",
    "        return {\"role\": \"tool\", \"content\": msg.content, \"tool_call_id\": msg.tool_call_id}\n",
    "    \n",
    "    else:\n",
    "\n",
    "        return {\"role\": \"user\", \"content\": str(msg)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3180c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8873eb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(State)\n",
    "\n",
    "mcp_servers = [\"http://localhost:8001/mcp\", \"http://localhost:8002/mcp\"]\n",
    "\n",
    "tool_descriptions = await get_tool_descriptions_from_mcp_servers(mcp_servers)\n",
    "\n",
    "workflow.add_node(\"agent_node\", agent_node)\n",
    "workflow.add_node(\"mcp_tool_node\", mcp_tool_node)\n",
    "\n",
    "workflow.add_edge(START, \"agent_node\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent_node\",\n",
    "    tool_router,\n",
    "    {\n",
    "        \"tools\": \"mcp_tool_node\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"mcp_tool_node\", \"agent_node\")\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e84ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e7518865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "27ca7a6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "3 validation errors for State\ntool_calls.0\n  Input should be a valid dictionary or instance of ToolCall [type=model_type, input_value=ToolCall(name='get_format...p://localhost:8001/mcp'), input_type=ToolCall]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_type\ntool_calls.1\n  Input should be a valid dictionary or instance of ToolCall [type=model_type, input_value=ToolCall(name='get_format...p://localhost:8001/mcp'), input_type=ToolCall]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_type\ntool_calls.2\n  Input should be a valid dictionary or instance of ToolCall [type=model_type, input_value=ToolCall(name='get_format...p://localhost:8001/mcp'), input_type=ToolCall]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_type",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m initial_state = {\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [{\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mCan i get some earphones for myself, a laptop bag for my wife and something cool for my kids?\u001b[39m\u001b[33m\"\u001b[39m}],\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mavailable_tools\u001b[39m\u001b[33m\"\u001b[39m: tool_descriptions\n\u001b[32m      4\u001b[39m }\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m graph.ainvoke(initial_state)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/AIML/SwirlAI/AI_bootcamp_summer_2025/01-ai-engineering-bootcamp/.venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py:2920\u001b[39m, in \u001b[36mPregel.ainvoke\u001b[39m\u001b[34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, **kwargs)\u001b[39m\n\u001b[32m   2917\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   2918\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2920\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.astream(\n\u001b[32m   2921\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   2922\u001b[39m     config,\n\u001b[32m   2923\u001b[39m     stream_mode=[\u001b[33m\"\u001b[39m\u001b[33mupdates\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   2924\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode == \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2925\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m stream_mode,\n\u001b[32m   2926\u001b[39m     print_mode=print_mode,\n\u001b[32m   2927\u001b[39m     output_keys=output_keys,\n\u001b[32m   2928\u001b[39m     interrupt_before=interrupt_before,\n\u001b[32m   2929\u001b[39m     interrupt_after=interrupt_after,\n\u001b[32m   2930\u001b[39m     **kwargs,\n\u001b[32m   2931\u001b[39m ):\n\u001b[32m   2932\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode == \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2933\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunk) == \u001b[32m2\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/AIML/SwirlAI/AI_bootcamp_summer_2025/01-ai-engineering-bootcamp/.venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py:2768\u001b[39m, in \u001b[36mPregel.astream\u001b[39m\u001b[34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2766\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m loop.amatch_cached_writes():\n\u001b[32m   2767\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2768\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner.atick(\n\u001b[32m   2769\u001b[39m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop.tasks.values() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t.writes],\n\u001b[32m   2770\u001b[39m     timeout=\u001b[38;5;28mself\u001b[39m.step_timeout,\n\u001b[32m   2771\u001b[39m     get_waiter=get_waiter,\n\u001b[32m   2772\u001b[39m     schedule_task=loop.aaccept_push,\n\u001b[32m   2773\u001b[39m ):\n\u001b[32m   2774\u001b[39m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[32m   2775\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m _output(\n\u001b[32m   2776\u001b[39m         stream_mode,\n\u001b[32m   2777\u001b[39m         print_mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2780\u001b[39m         asyncio.QueueEmpty,\n\u001b[32m   2781\u001b[39m     ):\n\u001b[32m   2782\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m o\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/AIML/SwirlAI/AI_bootcamp_summer_2025/01-ai-engineering-bootcamp/.venv/lib/python3.12/site-packages/langgraph/graph/branch.py:181\u001b[39m, in \u001b[36mBranch._aroute\u001b[39m\u001b[34m(self, input, config, reader, writer)\u001b[39m\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_aroute\u001b[39m(\n\u001b[32m    173\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    174\u001b[39m     \u001b[38;5;28minput\u001b[39m: Any,\n\u001b[32m   (...)\u001b[39m\u001b[32m    178\u001b[39m     writer: Writer,\n\u001b[32m    179\u001b[39m ) -> Runnable:\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m reader:\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m         value = \u001b[43mreader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    182\u001b[39m         \u001b[38;5;66;03m# passthrough additional keys from node to branch\u001b[39;00m\n\u001b[32m    183\u001b[39m         \u001b[38;5;66;03m# only doable when using dict states\u001b[39;00m\n\u001b[32m    184\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    185\u001b[39m             \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mdict\u001b[39m)\n\u001b[32m    186\u001b[39m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mdict\u001b[39m)\n\u001b[32m    187\u001b[39m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.input_schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    188\u001b[39m         ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/AIML/SwirlAI/AI_bootcamp_summer_2025/01-ai-engineering-bootcamp/.venv/lib/python3.12/site-packages/langgraph/pregel/read.py:90\u001b[39m, in \u001b[36mChannelRead.do_read\u001b[39m\u001b[34m(config, select, fresh, mapper)\u001b[39m\n\u001b[32m     85\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     86\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNot configured with a read function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     87\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMake sure to call in the context of a Pregel process\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     88\u001b[39m     )\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mapper:\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfresh\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     92\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m read(select, fresh)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/AIML/SwirlAI/AI_bootcamp_summer_2025/01-ai-engineering-bootcamp/.venv/lib/python3.12/site-packages/langgraph/graph/state.py:1222\u001b[39m, in \u001b[36m_coerce_state\u001b[39m\u001b[34m(schema, input)\u001b[39m\n\u001b[32m   1221\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_coerce_state\u001b[39m(schema: \u001b[38;5;28mtype\u001b[39m[Any], \u001b[38;5;28minput\u001b[39m: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m-> \u001b[39m\u001b[32m1222\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mschema\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/AIML/SwirlAI/AI_bootcamp_summer_2025/01-ai-engineering-bootcamp/.venv/lib/python3.12/site-packages/pydantic/main.py:253\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    252\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    255\u001b[39m     warnings.warn(\n\u001b[32m    256\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    257\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    259\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    260\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 3 validation errors for State\ntool_calls.0\n  Input should be a valid dictionary or instance of ToolCall [type=model_type, input_value=ToolCall(name='get_format...p://localhost:8001/mcp'), input_type=ToolCall]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_type\ntool_calls.1\n  Input should be a valid dictionary or instance of ToolCall [type=model_type, input_value=ToolCall(name='get_format...p://localhost:8001/mcp'), input_type=ToolCall]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_type\ntool_calls.2\n  Input should be a valid dictionary or instance of ToolCall [type=model_type, input_value=ToolCall(name='get_format...p://localhost:8001/mcp'), input_type=ToolCall]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_type",
      "During task with name 'agent_node' and id '7725f3da-e5b8-23d8-f5a8-29a0ce21c619'"
     ]
    }
   ],
   "source": [
    "initial_state = {\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Can i get some earphones for myself, a laptop bag for my wife and something cool for my kids?\"}],\n",
    "    \"available_tools\": tool_descriptions\n",
    "}\n",
    "result = await graph.ainvoke(initial_state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e94c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612460bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64447071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735e42ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5177c484",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b9ae1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a948ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def mcp_tool_node(state: State) -> str:\n",
    "\n",
    "    tool_messages = []\n",
    "\n",
    "    for i, tc in enumerate(state.tool_calls):\n",
    "\n",
    "        client = Client(tc.server)\n",
    "\n",
    "        async with client:\n",
    "\n",
    "            result = await client.call_tool(tc.name, tc.arguments)\n",
    "\n",
    "            tool_message = ToolMessage(\n",
    "                content=result,\n",
    "                tool_call_id=f\"call_{i}\"\n",
    "            )\n",
    "\n",
    "            tool_messages.append(tool_message)\n",
    "\n",
    "    return {\n",
    "        \"messages\": tool_messages\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d124c157",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "01-ai-engineering-bootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
